{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "from keras import initializers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import gensim, logging\n",
    "from gensim.models import word2vec\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy.random import randint\n",
    "from numpy import argmax\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 41\n",
    "epochs = 200\n",
    "hidden_units = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-6\n",
    "clip_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"filtered.txt\",\"r\") as readfile:\n",
    "    types = [line.split(\"_\") for line in readfile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "c=0\n",
    "#print (types)\n",
    "for i in range(len(types)):\n",
    "    X.append(types[i][0])\n",
    "    y.append(types[i][1])\n",
    "\n",
    "label = [k.strip(\"\\n\") for k in y]\n",
    "#print(label)\n",
    "X = [X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [k.strip(\"\\n\") for k in y]\n",
    "#print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(X, size=100, window=5, min_count=1, workers=4) #input shape=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = np.shape(X)\n",
    "dataset = []\n",
    "for i in range(n):\n",
    "    dataset.append(model.wv[X[0][i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "tags = le.fit(label)\n",
    "le.fit(label)\n",
    "\n",
    "tags=le.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, tags, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41874, 100) (10469, 100) (41874,) (10469,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "num_classes = len(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "X_train shape: (41874, 100, 1)\n",
      "41874 train samples\n",
      "10469 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = np.stack(X_train, axis = 0)\n",
    "print(np.shape(X_train.shape[0]))\n",
    "X_test = np.stack(X_test, axis = 0)\n",
    "print(np.shape(X_test.shape[0]))\n",
    "X_train = X_train.reshape(X_train.shape[0], -1, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(np.shape(X_train[0]))\n",
    "print(np.shape(X_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(hidden_units,\n",
    "                    activation='tanh',\n",
    "                    input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "rmsprop = RMSprop(lr=learning_rate)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=rmsprop,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41874 samples, validate on 10469 samples\n",
      "Epoch 1/200\n",
      "41874/41874 [==============================] - 132s 3ms/step - loss: 0.2708 - acc: 0.9231 - val_loss: 0.2704 - val_acc: 0.9231\n",
      "Epoch 2/200\n",
      "41874/41874 [==============================] - 133s 3ms/step - loss: 0.2699 - acc: 0.9231 - val_loss: 0.2693 - val_acc: 0.9231\n",
      "Epoch 3/200\n",
      "41874/41874 [==============================] - 88s 2ms/step - loss: 0.2686 - acc: 0.9231 - val_loss: 0.2679 - val_acc: 0.9231\n",
      "Epoch 4/200\n",
      "41874/41874 [==============================] - 78s 2ms/step - loss: 0.2668 - acc: 0.9231 - val_loss: 0.2657 - val_acc: 0.9231\n",
      "Epoch 5/200\n",
      "41874/41874 [==============================] - 79s 2ms/step - loss: 0.2639 - acc: 0.9231 - val_loss: 0.2618 - val_acc: 0.9231\n",
      "Epoch 6/200\n",
      "41874/41874 [==============================] - 81s 2ms/step - loss: 0.2581 - acc: 0.9231 - val_loss: 0.2530 - val_acc: 0.9231\n",
      "Epoch 7/200\n",
      "41874/41874 [==============================] - 83s 2ms/step - loss: 0.2383 - acc: 0.9231 - val_loss: 0.2095 - val_acc: 0.9231\n",
      "Epoch 8/200\n",
      "41874/41874 [==============================] - 85s 2ms/step - loss: 0.1745 - acc: 0.9273 - val_loss: 0.1649 - val_acc: 0.9296\n",
      "Epoch 9/200\n",
      "41874/41874 [==============================] - 84s 2ms/step - loss: 0.1611 - acc: 0.9300 - val_loss: 0.1589 - val_acc: 0.9296\n",
      "Epoch 10/200\n",
      "41874/41874 [==============================] - 84s 2ms/step - loss: 0.1553 - acc: 0.9300 - val_loss: 0.1537 - val_acc: 0.9296\n",
      "Epoch 11/200\n",
      "41874/41874 [==============================] - 85s 2ms/step - loss: 0.1511 - acc: 0.9300 - val_loss: 0.1507 - val_acc: 0.9296\n",
      "Epoch 12/200\n",
      "41874/41874 [==============================] - 85s 2ms/step - loss: 0.1488 - acc: 0.9300 - val_loss: 0.1489 - val_acc: 0.9296\n",
      "Epoch 13/200\n",
      "41874/41874 [==============================] - 85s 2ms/step - loss: 0.1474 - acc: 0.9300 - val_loss: 0.1478 - val_acc: 0.9296\n",
      "Epoch 14/200\n",
      "41874/41874 [==============================] - 85s 2ms/step - loss: 0.1465 - acc: 0.9300 - val_loss: 0.1470 - val_acc: 0.9296\n",
      "Epoch 15/200\n",
      "41874/41874 [==============================] - 85s 2ms/step - loss: 0.1458 - acc: 0.9300 - val_loss: 0.1464 - val_acc: 0.9296\n",
      "Epoch 16/200\n",
      "41874/41874 [==============================] - 85s 2ms/step - loss: 0.1452 - acc: 0.9300 - val_loss: 0.1459 - val_acc: 0.9296\n",
      "Epoch 17/200\n",
      "41874/41874 [==============================] - 85s 2ms/step - loss: 0.1448 - acc: 0.9300 - val_loss: 0.1455 - val_acc: 0.9296\n",
      "Epoch 18/200\n",
      "41874/41874 [==============================] - 85s 2ms/step - loss: 0.1445 - acc: 0.9300 - val_loss: 0.1453 - val_acc: 0.9296\n",
      "Epoch 19/200\n",
      "41874/41874 [==============================] - 85s 2ms/step - loss: 0.1443 - acc: 0.9300 - val_loss: 0.1450 - val_acc: 0.9296\n",
      "Epoch 20/200\n",
      "41874/41874 [==============================] - 86s 2ms/step - loss: 0.1441 - acc: 0.9300 - val_loss: 0.1448 - val_acc: 0.9296\n",
      "Epoch 21/200\n",
      "41874/41874 [==============================] - 86s 2ms/step - loss: 0.1439 - acc: 0.9300 - val_loss: 0.1447 - val_acc: 0.9296\n",
      "Epoch 22/200\n",
      "41874/41874 [==============================] - 85s 2ms/step - loss: 0.1437 - acc: 0.9300 - val_loss: 0.1446 - val_acc: 0.9296\n",
      "Epoch 23/200\n",
      "41874/41874 [==============================] - 85s 2ms/step - loss: 0.1436 - acc: 0.9300 - val_loss: 0.1444 - val_acc: 0.9296\n",
      "Epoch 24/200\n",
      "21504/41874 [==============>...............] - ETA: 39s - loss: 0.1433 - acc: 0.9299"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy.random import randint\n",
    "from numpy import argmax\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c709023075b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred.round())\n",
    "f1 = f1_score(y_test, y_pred.round(), average='macro')\n",
    "rc = recall_score(y_test, y_pred.round(), average='macro')\n",
    "pr = precision_score(y_test, y_pred.round(), average='macro')\n",
    "\n",
    "print(\"Accuracy = \",\"{0:.2f}\".format(acc))\n",
    "print(\"Precision = \",\"{0:.4f}\".format(pr))\n",
    "print(\"Recall = \",\"{0:.4f}\".format(rc))\n",
    "\n",
    "print(\"F1-score = \",\"{0:.4f}\".format(f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i ran on terminal. but this is the code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
