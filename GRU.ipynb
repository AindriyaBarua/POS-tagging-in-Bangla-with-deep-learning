{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "from keras import initializers\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import gensim, logging\n",
    "from gensim.models import word2vec\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy.random import randint\n",
    "from numpy import argmax\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 41\n",
    "epochs = 50\n",
    "hidden_units = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-6\n",
    "clip_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"filtered.txt\",\"r\") as readfile:\n",
    "    types = [line.split(\"_\") for line in readfile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "c=0\n",
    "#print (types)\n",
    "for i in range(len(types)):\n",
    "    X.append(types[i][0])\n",
    "    y.append(types[i][1])\n",
    "\n",
    "label = [k.strip(\"\\n\") for k in y]\n",
    "#print(label)\n",
    "X = [X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [k.strip(\"\\n\") for k in y]\n",
    "#print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(X, size=100, window=5, min_count=1, workers=4) #input shape=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = np.shape(X)\n",
    "dataset = []\n",
    "for i in range(n):\n",
    "    dataset.append(model.wv[X[0][i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "tags = le.fit(label)\n",
    "le.fit(label)\n",
    "\n",
    "tags=le.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, tags, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41874, 100) (10469, 100) (41874,) (10469,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "num_classes = len(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "X_train shape: (41874, 100, 1)\n",
      "41874 train samples\n",
      "10469 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = np.stack(X_train, axis = 0)\n",
    "print(np.shape(X_train.shape[0]))\n",
    "X_test = np.stack(X_test, axis = 0)\n",
    "print(np.shape(X_test.shape[0]))\n",
    "X_train = X_train.reshape(X_train.shape[0], -1, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(np.shape(X_train[0]))\n",
    "print(np.shape(X_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(hidden_units,\n",
    "                    activation='tanh',\n",
    "                    input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "rmsprop = RMSprop(lr=learning_rate)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=rmsprop,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41874 samples, validate on 10469 samples\n",
      "Epoch 1/50\n",
      "41874/41874 [==============================] - 58s 1ms/step - loss: 0.2706 - acc: 0.9231 - val_loss: 0.2701 - val_acc: 0.9231\n",
      "Epoch 2/50\n",
      "41874/41874 [==============================] - 62s 1ms/step - loss: 0.2696 - acc: 0.9231 - val_loss: 0.2690 - val_acc: 0.9231\n",
      "Epoch 3/50\n",
      "41874/41874 [==============================] - 64s 2ms/step - loss: 0.2684 - acc: 0.9231 - val_loss: 0.2677 - val_acc: 0.9231\n",
      "Epoch 4/50\n",
      "41874/41874 [==============================] - 63s 1ms/step - loss: 0.2669 - acc: 0.9231 - val_loss: 0.2662 - val_acc: 0.9231\n",
      "Epoch 5/50\n",
      "41874/41874 [==============================] - 64s 2ms/step - loss: 0.2652 - acc: 0.9231 - val_loss: 0.2642 - val_acc: 0.9231\n",
      "Epoch 6/50\n",
      "41874/41874 [==============================] - 66s 2ms/step - loss: 0.2631 - acc: 0.9231 - val_loss: 0.2618 - val_acc: 0.9231\n",
      "Epoch 7/50\n",
      "41874/41874 [==============================] - 67s 2ms/step - loss: 0.2603 - acc: 0.9231 - val_loss: 0.2588 - val_acc: 0.9231\n",
      "Epoch 8/50\n",
      "41874/41874 [==============================] - 70s 2ms/step - loss: 0.2569 - acc: 0.9231 - val_loss: 0.2548 - val_acc: 0.9231\n",
      "Epoch 9/50\n",
      "41874/41874 [==============================] - 65s 2ms/step - loss: 0.2522 - acc: 0.9231 - val_loss: 0.2494 - val_acc: 0.9231\n",
      "Epoch 10/50\n",
      "41874/41874 [==============================] - 64s 2ms/step - loss: 0.2456 - acc: 0.9231 - val_loss: 0.2416 - val_acc: 0.9231\n",
      "Epoch 11/50\n",
      "41874/41874 [==============================] - 64s 2ms/step - loss: 0.2357 - acc: 0.9231 - val_loss: 0.2290 - val_acc: 0.9231\n",
      "Epoch 12/50\n",
      "41874/41874 [==============================] - 66s 2ms/step - loss: 0.2181 - acc: 0.9231 - val_loss: 0.2044 - val_acc: 0.9231\n",
      "Epoch 13/50\n",
      "41874/41874 [==============================] - 71s 2ms/step - loss: 0.1786 - acc: 0.9244 - val_loss: 0.1570 - val_acc: 0.9296\n",
      "Epoch 14/50\n",
      "41874/41874 [==============================] - 74s 2ms/step - loss: 0.1553 - acc: 0.9300 - val_loss: 0.1556 - val_acc: 0.9296\n",
      "Epoch 15/50\n",
      "41874/41874 [==============================] - 71s 2ms/step - loss: 0.1540 - acc: 0.9300 - val_loss: 0.1545 - val_acc: 0.9296\n",
      "Epoch 16/50\n",
      "41874/41874 [==============================] - 71s 2ms/step - loss: 0.1529 - acc: 0.9300 - val_loss: 0.1534 - val_acc: 0.9296\n",
      "Epoch 17/50\n",
      "41874/41874 [==============================] - 71s 2ms/step - loss: 0.1519 - acc: 0.9300 - val_loss: 0.1524 - val_acc: 0.9296\n",
      "Epoch 18/50\n",
      "41874/41874 [==============================] - 72s 2ms/step - loss: 0.1510 - acc: 0.9300 - val_loss: 0.1517 - val_acc: 0.9296\n",
      "Epoch 19/50\n",
      "41874/41874 [==============================] - 71s 2ms/step - loss: 0.1502 - acc: 0.9300 - val_loss: 0.1509 - val_acc: 0.9296\n",
      "Epoch 20/50\n",
      "41874/41874 [==============================] - 70s 2ms/step - loss: 0.1495 - acc: 0.9300 - val_loss: 0.1503 - val_acc: 0.9296\n",
      "Epoch 21/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1489 - acc: 0.9300 - val_loss: 0.1497 - val_acc: 0.9296\n",
      "Epoch 22/50\n",
      "41874/41874 [==============================] - 71s 2ms/step - loss: 0.1484 - acc: 0.9300 - val_loss: 0.1492 - val_acc: 0.9296\n",
      "Epoch 23/50\n",
      "41874/41874 [==============================] - 70s 2ms/step - loss: 0.1479 - acc: 0.9300 - val_loss: 0.1487 - val_acc: 0.9296\n",
      "Epoch 24/50\n",
      "41874/41874 [==============================] - 72s 2ms/step - loss: 0.1474 - acc: 0.9300 - val_loss: 0.1482 - val_acc: 0.9296\n",
      "Epoch 25/50\n",
      "41874/41874 [==============================] - 70s 2ms/step - loss: 0.1470 - acc: 0.9300 - val_loss: 0.1479 - val_acc: 0.9296\n",
      "Epoch 26/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1466 - acc: 0.9300 - val_loss: 0.1475 - val_acc: 0.9296\n",
      "Epoch 27/50\n",
      "41874/41874 [==============================] - 70s 2ms/step - loss: 0.1463 - acc: 0.9300 - val_loss: 0.1471 - val_acc: 0.9296\n",
      "Epoch 28/50\n",
      "41874/41874 [==============================] - 71s 2ms/step - loss: 0.1459 - acc: 0.9300 - val_loss: 0.1468 - val_acc: 0.9296\n",
      "Epoch 29/50\n",
      "41874/41874 [==============================] - 70s 2ms/step - loss: 0.1456 - acc: 0.9300 - val_loss: 0.1465 - val_acc: 0.9296\n",
      "Epoch 30/50\n",
      "41874/41874 [==============================] - 70s 2ms/step - loss: 0.1454 - acc: 0.9300 - val_loss: 0.1462 - val_acc: 0.9296\n",
      "Epoch 31/50\n",
      "41874/41874 [==============================] - 70s 2ms/step - loss: 0.1451 - acc: 0.9300 - val_loss: 0.1460 - val_acc: 0.9296\n",
      "Epoch 32/50\n",
      "41874/41874 [==============================] - 70s 2ms/step - loss: 0.1449 - acc: 0.9300 - val_loss: 0.1458 - val_acc: 0.9296\n",
      "Epoch 33/50\n",
      "41874/41874 [==============================] - 70s 2ms/step - loss: 0.1447 - acc: 0.9300 - val_loss: 0.1456 - val_acc: 0.9296\n",
      "Epoch 34/50\n",
      "41874/41874 [==============================] - 70s 2ms/step - loss: 0.1445 - acc: 0.9300 - val_loss: 0.1454 - val_acc: 0.9296\n",
      "Epoch 35/50\n",
      "41874/41874 [==============================] - 72s 2ms/step - loss: 0.1443 - acc: 0.9300 - val_loss: 0.1452 - val_acc: 0.9296\n",
      "Epoch 36/50\n",
      "41874/41874 [==============================] - 71s 2ms/step - loss: 0.1442 - acc: 0.9300 - val_loss: 0.1451 - val_acc: 0.9296\n",
      "Epoch 37/50\n",
      "41874/41874 [==============================] - 72s 2ms/step - loss: 0.1441 - acc: 0.9300 - val_loss: 0.1450 - val_acc: 0.9296\n",
      "Epoch 38/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1439 - acc: 0.9300 - val_loss: 0.1449 - val_acc: 0.9296\n",
      "Epoch 39/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1438 - acc: 0.9300 - val_loss: 0.1448 - val_acc: 0.9296\n",
      "Epoch 40/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1438 - acc: 0.9300 - val_loss: 0.1447 - val_acc: 0.9296\n",
      "Epoch 41/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1437 - acc: 0.9300 - val_loss: 0.1446 - val_acc: 0.9296\n",
      "Epoch 42/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1436 - acc: 0.9300 - val_loss: 0.1445 - val_acc: 0.9296\n",
      "Epoch 43/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1435 - acc: 0.9300 - val_loss: 0.1445 - val_acc: 0.9296\n",
      "Epoch 44/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1435 - acc: 0.9300 - val_loss: 0.1444 - val_acc: 0.9296\n",
      "Epoch 45/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1434 - acc: 0.9300 - val_loss: 0.1443 - val_acc: 0.9296\n",
      "Epoch 46/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1433 - acc: 0.9300 - val_loss: 0.1443 - val_acc: 0.9296\n",
      "Epoch 47/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1433 - acc: 0.9300 - val_loss: 0.1442 - val_acc: 0.9296\n",
      "Epoch 48/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1433 - acc: 0.9300 - val_loss: 0.1442 - val_acc: 0.9296\n",
      "Epoch 49/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1432 - acc: 0.9300 - val_loss: 0.1441 - val_acc: 0.9296\n",
      "Epoch 50/50\n",
      "41874/41874 [==============================] - 69s 2ms/step - loss: 0.1432 - acc: 0.9300 - val_loss: 0.1441 - val_acc: 0.9296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e4c3406a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
