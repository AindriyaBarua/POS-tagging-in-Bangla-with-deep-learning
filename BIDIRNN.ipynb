{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import SimpleRNN, Bidirectional\n",
    "from keras import initializers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import gensim, logging\n",
    "from gensim.models import word2vec\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy.random import randint\n",
    "from numpy import argmax\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 41\n",
    "epochs = 50\n",
    "hidden_units = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-6\n",
    "clip_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"filtered.txt\",\"r\") as readfile:\n",
    "    types = [line.split(\"_\") for line in readfile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "c=0\n",
    "#print (types)\n",
    "for i in range(len(types)):\n",
    "    X.append(types[i][0])\n",
    "    y.append(types[i][1])\n",
    "\n",
    "label = [k.strip(\"\\n\") for k in y]\n",
    "#print(label)\n",
    "X = [X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [k.strip(\"\\n\") for k in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(X, size=100, window=5, min_count=1, workers=4) #input shape=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = np.shape(X)\n",
    "dataset = []\n",
    "for i in range(n):\n",
    "    dataset.append(model.wv[X[0][i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "tags = le.fit(label)\n",
    "le.fit(label)\n",
    "\n",
    "tags=le.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, tags, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41874, 100) (10469, 100) (41874,) (10469,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "num_classes = len(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "X_train shape: (41874, 100, 1)\n",
      "41874 train samples\n",
      "10469 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = np.stack(X_train, axis = 0)\n",
    "print(np.shape(X_train.shape[0]))\n",
    "X_test = np.stack(X_test, axis = 0)\n",
    "print(np.shape(X_test.shape[0]))\n",
    "X_train = X_train.reshape(X_train.shape[0], -1, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(np.shape(X_train[0]))\n",
    "print(np.shape(X_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_units,\n",
    "                    kernel_initializer=initializers.RandomNormal(stddev=0.001),\n",
    "                    recurrent_initializer=initializers.Identity(gain=1.0),\n",
    "                    activation='tanh',\n",
    "                    input_shape=X_train.shape[1:])))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "rmsprop = RMSprop(lr=learning_rate)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=rmsprop,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41874 samples, validate on 10469 samples\n",
      "Epoch 1/50\n",
      "41874/41874 [==============================] - 23s 549us/step - loss: 0.1742 - acc: 0.9282 - val_loss: 0.1487 - val_acc: 0.9296\n",
      "Epoch 2/50\n",
      "41874/41874 [==============================] - 27s 639us/step - loss: 0.1461 - acc: 0.9300 - val_loss: 0.1460 - val_acc: 0.9296\n",
      "Epoch 3/50\n",
      "41874/41874 [==============================] - 27s 652us/step - loss: 0.1445 - acc: 0.9300 - val_loss: 0.1449 - val_acc: 0.9296\n",
      "Epoch 4/50\n",
      "41874/41874 [==============================] - 28s 658us/step - loss: 0.1438 - acc: 0.9300 - val_loss: 0.1445 - val_acc: 0.9296\n",
      "Epoch 5/50\n",
      "41874/41874 [==============================] - 27s 653us/step - loss: 0.1434 - acc: 0.9300 - val_loss: 0.1443 - val_acc: 0.9296\n",
      "Epoch 6/50\n",
      "41874/41874 [==============================] - 27s 642us/step - loss: 0.1432 - acc: 0.9300 - val_loss: 0.1440 - val_acc: 0.9296\n",
      "Epoch 7/50\n",
      "41874/41874 [==============================] - 28s 674us/step - loss: 0.1431 - acc: 0.9300 - val_loss: 0.1439 - val_acc: 0.9296\n",
      "Epoch 8/50\n",
      "41874/41874 [==============================] - 46s 1ms/step - loss: 0.1430 - acc: 0.9300 - val_loss: 0.1439 - val_acc: 0.9296\n",
      "Epoch 9/50\n",
      "41874/41874 [==============================] - 47s 1ms/step - loss: 0.1429 - acc: 0.9300 - val_loss: 0.1440 - val_acc: 0.9296\n",
      "Epoch 10/50\n",
      "41874/41874 [==============================] - 47s 1ms/step - loss: 0.1429 - acc: 0.9300 - val_loss: 0.1438 - val_acc: 0.9296\n",
      "Epoch 11/50\n",
      "41874/41874 [==============================] - 47s 1ms/step - loss: 0.1428 - acc: 0.9300 - val_loss: 0.1437 - val_acc: 0.9296\n",
      "Epoch 12/50\n",
      "41874/41874 [==============================] - 48s 1ms/step - loss: 0.1428 - acc: 0.9300 - val_loss: 0.1438 - val_acc: 0.9296\n",
      "Epoch 13/50\n",
      "41874/41874 [==============================] - 48s 1ms/step - loss: 0.1428 - acc: 0.9300 - val_loss: 0.1437 - val_acc: 0.9296\n",
      "Epoch 14/50\n",
      "41874/41874 [==============================] - 48s 1ms/step - loss: 0.1428 - acc: 0.9300 - val_loss: 0.1437 - val_acc: 0.9296\n",
      "Epoch 15/50\n",
      "41874/41874 [==============================] - 51s 1ms/step - loss: 0.1428 - acc: 0.9300 - val_loss: 0.1437 - val_acc: 0.9296\n",
      "Epoch 16/50\n",
      "41874/41874 [==============================] - 48s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1437 - val_acc: 0.9296\n",
      "Epoch 17/50\n",
      "41874/41874 [==============================] - 48s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1437 - val_acc: 0.9296\n",
      "Epoch 18/50\n",
      "41874/41874 [==============================] - 48s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1436 - val_acc: 0.9296\n",
      "Epoch 19/50\n",
      "41874/41874 [==============================] - 48s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1437 - val_acc: 0.9296\n",
      "Epoch 20/50\n",
      "41874/41874 [==============================] - 49s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1436 - val_acc: 0.9296\n",
      "Epoch 21/50\n",
      "41874/41874 [==============================] - 49s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1438 - val_acc: 0.9296\n",
      "Epoch 22/50\n",
      "41874/41874 [==============================] - 49s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1436 - val_acc: 0.9296\n",
      "Epoch 23/50\n",
      "41874/41874 [==============================] - 49s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1436 - val_acc: 0.9296\n",
      "Epoch 24/50\n",
      "41874/41874 [==============================] - 50s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1437 - val_acc: 0.9296\n",
      "Epoch 25/50\n",
      "41874/41874 [==============================] - 49s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1436 - val_acc: 0.9296\n",
      "Epoch 26/50\n",
      "41874/41874 [==============================] - 49s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1436 - val_acc: 0.9296\n",
      "Epoch 27/50\n",
      "41874/41874 [==============================] - 50s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1437 - val_acc: 0.9296\n",
      "Epoch 28/50\n",
      "41874/41874 [==============================] - 50s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1436 - val_acc: 0.9296\n",
      "Epoch 29/50\n",
      "41874/41874 [==============================] - 50s 1ms/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.1436 - val_acc: 0.9296\n",
      "Epoch 30/50\n",
      "12704/41874 [========>.....................] - ETA: 31s - loss: 0.1429 - acc: 0.9289"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
